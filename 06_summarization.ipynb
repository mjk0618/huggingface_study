{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter6 ìš”ì•½\n",
    "## 6.1 CNN/DailyMail ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŠ¹ì„±: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "print(f\"íŠ¹ì„±: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì‚¬ (500ê°œ ë¬¸ì ë°œì·Œ, ì´ ê¸¸ì´: 2527):\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as s\n",
      "\n",
      "ìš”ì•½ (ê¸¸ì´: 217):\n",
      "Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][0]\n",
    "print(f\"\"\"ê¸°ì‚¬ (500ê°œ ë¬¸ì ë°œì·Œ, ì´ ê¸¸ì´: {len(sample['article'])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f\"\\nìš”ì•½ (ê¸¸ì´: {len(sample['highlights'])}):\")\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "# ë”•ì…”ë„ˆë¦¬ì— ê° ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset[\"train\"]:\n",
    "    if sample[\"article\"].startswith(\"(CNN)  -- Usain Bolt rounded\"):\n",
    "        print(sample[\"article\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kang\n",
      "[nltk_data]     MinJae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fig.', '2 shows a U.S.A. map.']\n",
      "['Fig. 2 shows a U.S.A. map.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "\n",
    "string = \"Fig. 2 shows a U.S.A. map.\"\n",
    "\n",
    "print(sent_tokenize(string))\n",
    "\n",
    "punkt_param = PunktParameters()\n",
    "abbreviation = ['u.s.a', 'fig']\n",
    "punkt_param.abbrev_types = set(abbreviation)\n",
    "tokenizer = PunktSentenceTokenizer(punkt_param)\n",
    "\n",
    "print(tokenizer.tokenize(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 ìš”ì•½ ê¸°ì¤€ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(\n",
    "    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': 'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\\nHere, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\\nMIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"',\n",
       " 'gpt2': 'Here\\'s a more \"interesting\" story CNN.com was unable to access.\\nThis story in the Miami Herald\\xa0 is even more disturbing.\\nA video report at 6:00 \\xa0of Leifman\\'s office shows a video of a mentally ill inmate breaking through the bars of a jail cell and making a break for it.\\nThe\\xa0 Miami Herald headline above tells you everything'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c5c4027f0e4c08860e909667873a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kang MinJae\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddc7a4a8fb8451c84810fdb397683a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e18bdc8d7d24da1a2d47dfa612fe7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ee373d238047c888af5bd022b980c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de3d48020d84fedbddb7e67315081c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c01d93e3ede4a7199fe3e656836cc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b53439de3248f7beae436418e73d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bd3440f5e94c44a811e9eb538d270c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)neration_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413ef25ce2e3481f931f899d57dde875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705de744e94b47c08961f9d2fe668444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243b0bde8e3444afa7817b89574a6f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 PEGASUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b583e6cf38b845a5a12a28d10efc65f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d24e8038852483fbde5a96cc4fc92b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701246a4bf5c45d894646a4cb6d43a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)neration_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0befed7bbffd44f1adf5b14d81ae4294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6365ee0a3bc34d5baa7c3f23dd349e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ve/main/spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66e2dd39e9c4d909d5f17259ec99098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 ìš”ì•½ ê²°ê³¼ ë¹„êµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUD TRUTH\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "BASELINE\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n",
      "\n",
      "GPT2\n",
      "Here's a more \"interesting\" story CNN.com was unable to access.\n",
      "This story in the Miami HeraldÂ  is even more disturbing.\n",
      "A video report at 6:00 Â of Leifman's office shows a video of a mentally ill inmate breaking through the bars of a jail cell and making a break for it.\n",
      "TheÂ  Miami Herald headline above tells you everything\n",
      "\n",
      "T5\n",
      "mentally ill inmates are housed on the ninth floor of a florida jail .\n",
      "most face drug charges or charges of assaulting an officer .\n",
      "judge says arrests often result from confrontations with police .\n",
      "one-third of all people in Miami-dade county jails are mental ill .\n",
      "\n",
      "BART\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n",
      "\n",
      "PEGASUS\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"<n>The ninth floor is where they're held until they're ready to appear in court.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "They end up on the ninth floor severely mentally disturbed .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUD TRUTH\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 ìƒì„±ëœ í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€í•˜ê¸°\n",
    "### 6.4.1 BLEU\n",
    "ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ì–¼ë§ˆë‚˜ ë§ì€ í† í°ì´ ì°¸ì¡° í…ìŠ¤íŠ¸ í† í°ê³¼ ì™„ë²½í•˜ê²Œ ë˜‘ê°™ì´ ì •ë ¬ëëŠ”ì§€ í™•ì¸í•˜ëŠ” ëŒ€ì‹ , ë‹¨ì–´ ë˜ëŠ” n-ê·¸ë¨ì„ ì²´í¬í•©ë‹ˆë‹¤. ì •ë°€ë„ë¥¼ ê·¼ê°„ìœ¼ë¡œ í•˜ëŠ” ì§€í‘œì¸ë°, ë‘ í…ìŠ¤íŠ¸ë¥¼ ë¹„êµí•  ë•Œ ì°¸ì¡° í…ìŠ¤íŠ¸ì— ìˆëŠ” ë‹¨ì–´ê°€ ìƒì„±ëœ í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í•˜ëŠ”ì§€ ì¹´ìš´íŠ¸í•˜ê³ , ìƒì„±ëœ í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì—” ë¬¸ì œê°€ ìˆëŠ”ë°, ìƒì„±ëœ í…ìŠ¤íŠ¸ì— ë™ì¼ ë‹¨ì–´ê°€ ë°˜ë³µë˜ê³  ì´ ë‹¨ì–´ê°€ ì°¸ì¡° í…ìŠ¤íŠ¸ì— ë“±ì¥í•˜ë©´, ì •ë°€ë„ê°€ 1ì´ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ BLEU ë…¼ë¬¸ì—ì„œëŠ” ë‹¨ì–´ë¥¼ ì°¸ì¡° í…ìŠ¤íŠ¸ì— ë“±ì¥í•œ íšŸìˆ˜ë§Œí¼ë§Œ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´ ì°¸ì¡° í…ìŠ¤íŠ¸ì™€ ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ì•„ë˜ì™€ ê°™ì„ ë•Œ, ì •ë°€ë„ëŠ” ìˆ˜ì‹ê³¼ ê°™ì´ ê³„ì‚°ë©ë‹ˆë‹¤. \\\n",
    "\\\n",
    "ì°¸ì¡° í…ìŠ¤íŠ¸ : `the cat is on the mat` \\\n",
    "ìƒì„±ëœ í…ìŠ¤íŠ¸ : `the the the the the the`\n",
    "\n",
    "$$p_{vanilla} = {6\\over6}$$\n",
    "$$p_{mod} = {2\\over6}$$\n",
    "\n",
    "ì´ë¥¼ í™•ì¥í•˜ì—¬, ë‹¨ì–´ ë¿ë§Œ ì•„ë‹ˆë¼ n-ê·¸ë¨ë„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\\n",
    "ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ $snt$, ì°¸ì¡° ë¬¸ì¥ì„ $snt'$ë¼ê³  í•  ë•Œ, n-ê·¸ë¨ì— ëŒ€í•œ ì •ë°€ë„ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "p_n = {{\\sum_{n-gram \\in snt'}Count_{clip}(n-gram)}\\over{\\sum_{n-gram \\in snt}Count_(n-gram)}}\n",
    "$$\n",
    "\n",
    "ë°˜ë³µì ì¸ ìƒì„±ì—ëŠ” ì ìˆ˜ë¥¼ ì£¼ì§€ ì•Šë„ë¡ ë¶„ìì˜ ì¹´ìš´íŠ¸ëŠ” í´ë¦¬í•‘í•©ë‹ˆë‹¤. ì•ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´, ìƒì„±ëœ ë¬¸ì¥ì—ì„œ n-ê·¸ë¨ì˜ ë“±ì¥ íšŸìˆ˜ë¥¼ ì¹´ìš´íŠ¸ í•˜ëŠ” ê²ƒì´ ì°¸ì¡° ë¬¸ì¥ì— ë‚˜íƒ€ë‚œ íšŸìˆ˜ë¡œ ì œí•œëœë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. \\\n",
    "\n",
    "ì¼ë°˜ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ëŠ” í‰ê°€í•  ìƒ˜í”Œì´ í•˜ë‚˜ ì´ìƒì´ê¸° ë•Œë¬¸ì— ë§ë­‰ì¹˜ $C$ì— ìˆëŠ” ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ì„œëŠ” ì‹ì´ ë‹¤ìŒê³¼ ê°™ì´ í™•ì¥ë©ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "p_n = {{\\sum_{snt' \\in C}\\sum_{n-gram \\in snt'}Count_{clip}(n-gram)}\\over{\\sum_{snt \\in C}\\sum_{n-gram \\in snt}Count_(n-gram)}}\n",
    "$$\n",
    "\n",
    "ìœ„ ì‹ì€ ì¬í˜„ìœ¨ì€ ê³ ë ¤í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì§§ì€ ì‹œí€€ìŠ¤ê°€ ê¸´ ë¬¸ì¥ë³´ë‹¤ ìœ ë¦¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ **ë¸Œë ˆë¹„í‹° í˜ë„í‹°**(brevity penalty)ê°€ ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "BR = min(1, e^{1-\\ell_{ref}/\\ell_{gen}})\n",
    "$$\n",
    "\n",
    "ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ $\\ell_{gen}$ê°€ ì°¸ì¡° í…ìŠ¤íŠ¸ $\\ell_{ref}$ë³´ë‹¤ ë” ì§§ì„ ë•Œ ë•Œ ì§€ìˆ˜ í•­ì´ ì‘ì•„ì§‘ë‹ˆë‹¤. ë”°ë¼ì„œ BPì˜ ê°’ë„ ì‘ì•„ì§‘ë‹ˆë‹¤. \\\n",
    "ì¬í˜„ìœ¨ì„ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” ì´ìœ ëŠ” ë²ˆì—­ ë°ì´í„°ì…‹ì—ëŠ” ë³´í†µ ì—¬ëŸ¬ ê°œì˜ ì°¸ì¡° ë¬¸ì¥ì´ ìˆëŠ”ë°, ì¬í˜„ìœ¨ì„ ì¸¡ì •í•  ê²½ìš° ì°¸ì¡° ë¬¸ì¥ì— ìˆëŠ” ë‹¨ì–´ë¥¼ ëª¨ë‘ ì‚¬ìš©í•  ê²½ìš° ê°€ì‚°ì ì´ ë¶€ì—¬ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´ `Good Morning` ì´ë¼ëŠ” ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•  ë•Œ, ë°ì´í„°ì…‹ì— ë‹¤ìŒê³¼ ê°™ì´ ì°¸ì¡° ë¬¸ì¥ì´ ì„¸ ê°œê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "1. ì•ˆë…•í•˜ì„¸ìš”!\n",
    "2. ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”!\n",
    "3. ì•„ì¹¨ì´ ë°ì•˜ì–´ìš”!\n",
    "\n",
    "ì´ ë•Œ, ë²ˆì—­ëœ ë¬¸ì¥ì´ ì•ˆë…•í•˜ì„¸ìš”! `ì¢‹ì€ ì•„ì¹¨ì´ ë°ì•˜ì–´ìš”!`ì™€ ê°™ì´ ë²ˆì—­ë˜ë©´ ë” ë†’ì€ ì ìˆ˜ê°€ ë¶€ì—¬ë˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•ì—ì„œ ê³ ë ¤í•œ ëª¨ë“  ê²ƒì„ í•©ì¹œ BLEU ì ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "\\textrm{BLEU}-N = BR \\times \\left(\\prod_{n=1}^N p_n \\right)^{1/N}\n",
    "$$\n",
    "\n",
    "BLEUëŠ” ë™ì˜ì–´ë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë§¤ ë‹¨ê³„ì—ì„œ í•œê³„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1396c923b8f448018f9f8c8b52da8e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='c', min=1), IntSlider(value=50, description='r', min=1)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "\n",
    "def brevity_penalty(c, r):\n",
    "    BP = 1 if c > r else np.exp(1 - r / c)\n",
    "    \n",
    "    c_values = np.linspace(0.1, 2 * max(c, r), 400)  \n",
    "    BP_values = np.where(c_values > r, 1, np.exp(1 - r / c_values))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), dpi=100)\n",
    "    plt.plot(c_values, BP_values, label='Brevity Penalty curve', color='blue')\n",
    "    plt.axhline(y=1, color='gray', linestyle='--', lw=0.5)\n",
    "    plt.axvline(x=r, color='red', linestyle='--', label=f'Reference Length (r) = {r}')\n",
    "    plt.axvline(x=c, color='green', linestyle='--', label=f'Candidate Length (c) = {c}')\n",
    "    plt.scatter(c, BP, color='black', s=70, zorder=5)\n",
    "    plt.xlabel('Candidate Length')\n",
    "    plt.ylabel('Brevity Penalty (BP)')\n",
    "    plt.title('Brevity Penalty as function of Candidate Length')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(brevity_penalty, c=(1, 100), r=(1, 100))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì°¸ì¡° ë¬¸ì¥ì˜ ê¸¸ì´         ìƒì„±ëœ ë¬¸ì¥ì˜ ê¸¸ì´         ë¸Œë ˆë¹„í‹° í˜ë„í‹°\n",
      "50                      5                         0.00012340980408667956\n",
      "50                      25                        0.36787944117144233\n",
      "50                      50                        1.0\n",
      "50                      100                       1\n",
      "50                      150                       1\n"
     ]
    }
   ],
   "source": [
    "ref_len = 50\n",
    "can_lens = [5, 25, 50, 100, 150]\n",
    "\n",
    "print(\"ì°¸ì¡° ë¬¸ì¥ì˜ ê¸¸ì´         ìƒì„±ëœ ë¬¸ì¥ì˜ ê¸¸ì´         ë¸Œë ˆë¹„í‹° í˜ë„í‹°\")\n",
    "for can_len in can_lens:\n",
    "    BP = 1 if can_len > ref_len else np.exp(1 - ref_len / can_len)\n",
    "    print(f\"{ref_len:<23} {can_len:<25} {BP}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kang MinJae\\AppData\\Local\\Temp\\ipykernel_4044\\3278324519.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a372682a06d44f899e5269ad12838075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>ìµœì¢… BLEU ì ìˆ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "      <td>ë§¤ì¹­ëœ n-ê·¸ë¨ì˜ ê°œìˆ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "      <td>ê°€ëŠ¥í•œ n-ê·¸ë¨ì˜ ì´ ê°œìˆ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "      <td>ê° n-ê·¸ë¨ì— ëŒ€í•œ ì •ë°€ë„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ë¸Œë ˆë¹„í‹° í˜ë„í‹° ê°’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "      <td>ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "      <td>ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ê¸¸ì´</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value     Description\n",
       "score                          0.0      ìµœì¢… BLEU ì ìˆ˜\n",
       "counts                [2, 0, 0, 0]    ë§¤ì¹­ëœ n-ê·¸ë¨ì˜ ê°œìˆ˜\n",
       "totals                [6, 5, 4, 3]  ê°€ëŠ¥í•œ n-ê·¸ë¨ì˜ ì´ ê°œìˆ˜\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]  ê° n-ê·¸ë¨ì— ëŒ€í•œ ì •ë°€ë„\n",
       "bp                             1.0      ë¸Œë ˆë¹„í‹° í˜ë„í‹° ê°’\n",
       "sys_len                          6     ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´\n",
       "ref_len                          6      ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ê¸¸ì´"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "descriptions = {\n",
    "    \"score\": \"ìµœì¢… BLEU ì ìˆ˜\",\n",
    "    \"counts\": \"ë§¤ì¹­ëœ n-ê·¸ë¨ì˜ ê°œìˆ˜\",\n",
    "    \"totals\": \"ê°€ëŠ¥í•œ n-ê·¸ë¨ì˜ ì´ ê°œìˆ˜\",\n",
    "    \"precisions\": \"ê° n-ê·¸ë¨ì— ëŒ€í•œ ì •ë°€ë„\",\n",
    "    \"bp\": \"ë¸Œë ˆë¹„í‹° í˜ë„í‹° ê°’\",\n",
    "    \"sys_len\": \"ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´\",\n",
    "    \"ref_len\": \"ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ê¸¸ì´\"\n",
    "}\n",
    "\n",
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "df[\"Description\"] = df.index.map(descriptions)  # Map keys to descriptions\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`smooth_value`ë¥¼ ì‚¬ìš©í•˜ë©´ ë¶„ìì— ìƒìˆ˜ ê°’ì„ ì¶”ê°€í•©ë‹ˆë‹¤. `smooth_method=\"floor\"`ì¼ ê²½ìš° `smooth_value`ëŠ” $0.1$ì´ ë©ë‹ˆë‹¤. \\\n",
    "ì¦‰ ë¶„ìì— $+0.1$ì„ í•˜ì—¬ $p_n$ì„ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "p_n = \\frac{\\text{n-grams count in reference text} + \\text{smooth value(=0.1)}}{\\text{n-grams in generated text}}\n",
    "$$\n",
    "\n",
    "ë”°ë¼ì„œ bigramì—ì„œ ê²¹ì¹˜ëŠ” bigramì´ í•˜ë‚˜ë„ ì—†ì§€ë§Œ, ì•„ë˜ì™€ ê°™ì´ `smooth_value`ì— ì˜í•´ precisionì´ $\\frac{0.1}{5} = 0.2$ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>4.854918</td>\n",
       "      <td>ìµœì¢… BLEU ì ìˆ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "      <td>ë§¤ì¹­ëœ n-ê·¸ë¨ì˜ ê°œìˆ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "      <td>ê°€ëŠ¥í•œ n-ê·¸ë¨ì˜ ì´ ê°œìˆ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 2.0, 2.5, 3.33]</td>\n",
       "      <td>ê° n-ê·¸ë¨ì— ëŒ€í•œ ì •ë°€ë„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ë¸Œë ˆë¹„í‹° í˜ë„í‹° ê°’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "      <td>ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "      <td>ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ê¸¸ì´</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value     Description\n",
       "score                      4.854918      ìµœì¢… BLEU ì ìˆ˜\n",
       "counts                 [2, 0, 0, 0]    ë§¤ì¹­ëœ n-ê·¸ë¨ì˜ ê°œìˆ˜\n",
       "totals                 [6, 5, 4, 3]  ê°€ëŠ¥í•œ n-ê·¸ë¨ì˜ ì´ ê°œìˆ˜\n",
       "precisions  [33.33, 2.0, 2.5, 3.33]  ê° n-ê·¸ë¨ì— ëŒ€í•œ ì •ë°€ë„\n",
       "bp                              1.0      ë¸Œë ˆë¹„í‹° í˜ë„í‹° ê°’\n",
       "sys_len                           6     ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´\n",
       "ref_len                           6      ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ê¸¸ì´"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\")\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "df[\"Description\"] = df.index.map(descriptions)  # Map keys to descriptions\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 ROUGE\n",
    "\n",
    "ROGUE ì ìˆ˜ëŠ” ì •ë°€ë„ë³´ë‹¤ ì¬í˜„ìœ¨ì´ ì •í™•í•œ ìš”ì•½ ê°™ì€ íƒœìŠ¤í¬ë¥¼ ìœ„í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. n-ê·¸ë¨ì´ ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í•˜ëŠ”ì§€ ë¹„êµí•œë‹¤ëŠ” ì ì—ì„œ BLEU ì ìˆ˜ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ, ì°¸ì¡° í…ìŠ¤íŠ¸ì— ìˆëŠ” n-ê·¸ë¨ì´ ìƒì„±ëœ í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ë§ì´ ë“±ì¥í•˜ëŠ”ì§€ë„ í™•ì¸í•œë‹¤ëŠ” ì ì´ ë‹¤ë¦…ë‹ˆë‹¤. ë‹¤ìŒì´ ì›ë˜ ROUGE ì ìˆ˜ ê³µì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "\\textrm{ROUGE}-N = {{\\sum_{snt' \\in C}\\sum_{n-gram \\in snt'}Count_{match}(n-gram)}\\over{\\sum_{snt' \\in C}\\sum_{n-gram \\in snt'}Count_(n-gram)}}\n",
    "$$\n",
    "\n",
    "ê·¸ëŸ°ë° ì •ë°€ë„ë¥¼ ì™„ì „íˆ ì œê±°í•˜ë©´ ë¶€ì •ì ì¸ ì˜í–¥ì´ ì»¤ì§ì„ ë°œê²¬í•˜ì˜€ê³ , í´ë¦¬í•‘ ì¹´ìš´íŠ¸ë¥¼ í•˜ì§€ ì•ŠëŠ” BLEU ê³µì‹ìœ¼ë¡œ ëŒì•„ê°€ ì •ë°€ë„ë¥¼ ì¸¡ì •í•œ ë‹¤ìŒ ìœ„ì˜ ROUGEì‹ì—ì„œ êµ¬í•œ ì¬í˜„ìœ¨ ì ìˆ˜ë¥¼ ì¡°í™” í‰ê· í•œ $\\textrm{F}_1$-ì ìˆ˜ë¥¼ ROUGE ì ìˆ˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ROUGEëŠ” ê°€ì¥ ê¸´ ê³µí†µ ë¶€ë¶„ ì‹œí€€ìŠ¤(longest common subsequence, LCS)ë¥¼ ì¸¡ì •í•˜ëŠ” ë³„ë„ì˜ ì ìˆ˜ì¸ ROUGE-Lì´ ìˆìŠµë‹ˆë‹¤. ë‘ ìƒ˜í”Œ ì‚¬ì´ì—ì„œ ì´ ê°’ì„ ë¹„êµí•  ë•Œ, ê¸´ í…ìŠ¤íŠ¸ê°€ ìœ ë¦¬í•˜ë¯€ë¡œ ì •ê·œí™”ê°€ í•„ìš”í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ROUGE ê°œë°œìëŠ” F-ì ìˆ˜ì™€ ê°™ì€ ë°©ì‹ì„ ê³ ì•ˆí•˜ì˜€ê³ , ë‹¤ìŒê³¼ ê°™ì´ ì°¸ì¡° í…ìŠ¤íŠ¸ì™€ ìƒì„± í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ë¡œ LCSë¥¼ ì •ê·œí™”í•œ ë‹¤ìŒ ì •ê·œí™”ëœ ì ìˆ˜ë¥¼ í˜¼í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "R_{LCS} = \\frac{LCS(X, Y)}{m}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{LCS} = \\frac{LCS(X, Y)}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_{LCS} = \\frac{(1 + \\beta^2)R_{LCS}P_{LCS}}{R_{LCS}+\\beta^2P_{LCS}} ~~~~~~~~ (\\textrm{where, }\\beta = P_{LCS} / R_{LCS})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.288288</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.288288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.323232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714\n",
       "gpt2      0.288288  0.018349  0.162162   0.288288\n",
       "t5        0.382979  0.130435  0.255319   0.382979\n",
       "bart      0.475248  0.222222  0.316832   0.415842\n",
       "pegasus   0.323232  0.206186  0.282828   0.323232"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(predictions=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 CNN/DailyMail ë°ì´í„°ì…‹ì—ì„œ PEGASUS í‰ê°€í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text=\"article\",\n",
    "                                column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "                     references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.389276</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.245061</td>\n",
       "      <td>0.354239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.389276  0.171296  0.245061   0.354239"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "\n",
    "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\" list_of_elementsë¡œë¶€í„° batch_size í¬ê¸°ì˜ ì²­í¬ë¥¼ ì—°ì†ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. \"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n",
    "                           padding=\"max_length\", return_tensors=\"pt\")\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                                   attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                                   length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                              clean_up_tokenization_spaces=True)\n",
    "                            for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "    \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa49e6297624455a939b4bdea27c40be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>model_ckpt = <span style=\"color: #808000; text-decoration-color: #808000\">\"google/pegasus-cnn_dailymail\"</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>tokenizer = AutoTokenizer.from_pretrained(model_ckpt)                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 6 score = evaluate_summaries_pegasus(test_sampled, rouge_metric,                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>model, tokenizer, batch_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>rouge_dict = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>((rn, score[rn].mid.fmeasure) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> rn <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> rouge_names)                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate_summaries_pegasus</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">24</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 â”‚   â”‚   </span>inputs = tokenizer(article_batch, max_length=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1024</span>, truncation=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>padding=<span style=\"color: #808000; text-decoration-color: #808000\">\"max_length\"</span>, return_tensors=<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 â”‚   â”‚   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>24 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>summaries = model.generate(input_ids=inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"input_ids\"</span>].to(device),                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>attention_mask=inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"attention_mask\"</span>].to(device),      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>length_penalty=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.8</span>, num_beams=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>, max_length=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">128</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Kang </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span>  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 â”‚   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 â”‚   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Kang </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1604</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1601 â”‚   â”‚   â”‚   â”‚   </span>**model_kwargs,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1602 â”‚   â”‚   â”‚   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1603 â”‚   â”‚   â”‚   # 13. run beam search</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1604 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.beam_search(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1605 â”‚   â”‚   â”‚   â”‚   </span>input_ids,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1606 â”‚   â”‚   â”‚   â”‚   </span>beam_scorer,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1607 â”‚   â”‚   â”‚   â”‚   </span>logits_processor=logits_processor,                                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Kang </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2955</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">beam_search</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2952 â”‚   â”‚   â”‚   </span>next_tokens = next_tokens % vocab_size                                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2953 â”‚   â”‚   â”‚   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2954 â”‚   â”‚   â”‚   # stateless</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>2955 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>beam_outputs = beam_scorer.process(                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2956 â”‚   â”‚   â”‚   â”‚   </span>input_ids,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2957 â”‚   â”‚   â”‚   â”‚   </span>next_token_scores,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2958 â”‚   â”‚   â”‚   â”‚   </span>next_tokens,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Kang </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\beam_se</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">arch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">238</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">process</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">235 â”‚   â”‚   â”‚   </span>eos_token_id = [eos_token_id]                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">236 â”‚   â”‚   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">237 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch_idx, beam_hyp <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._beam_hyps):                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>238 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._done[batch_idx]:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_beams &lt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(beam_hyp):                                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 â”‚   â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Batch can only be done if at least {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_beam   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">241 â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> eos_token_id <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> pad_token_id <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 3 \u001b[0mmodel_ckpt = \u001b[33m\"\u001b[0m\u001b[33mgoogle/pegasus-cnn_dailymail\u001b[0m\u001b[33m\"\u001b[0m                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 4 \u001b[0mtokenizer = AutoTokenizer.from_pretrained(model_ckpt)                                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 5 \u001b[0mmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)                        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 6 score = evaluate_summaries_pegasus(test_sampled, rouge_metric,                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mmodel, tokenizer, batch_size=\u001b[94m8\u001b[0m)                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 8 \u001b[0mrouge_dict = \u001b[96mdict\u001b[0m((rn, score[rn].mid.fmeasure) \u001b[94mfor\u001b[0m rn \u001b[95min\u001b[0m rouge_names)                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 9 \u001b[0m                                                                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m in \u001b[92mevaluate_summaries_pegasus\u001b[0m:\u001b[94m24\u001b[0m                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0minputs = tokenizer(article_batch, max_length=\u001b[94m1024\u001b[0m, truncation=\u001b[94mTrue\u001b[0m,                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mpadding=\u001b[33m\"\u001b[0m\u001b[33mmax_length\u001b[0m\u001b[33m\"\u001b[0m, return_tensors=\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m)                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m24 \u001b[2mâ”‚   â”‚   \u001b[0msummaries = model.generate(input_ids=inputs[\u001b[33m\"\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m\"\u001b[0m].to(device),                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mattention_mask=inputs[\u001b[33m\"\u001b[0m\u001b[33mattention_mask\u001b[0m\u001b[33m\"\u001b[0m].to(device),      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mlength_penalty=\u001b[94m0.8\u001b[0m, num_beams=\u001b[94m8\u001b[0m, max_length=\u001b[94m128\u001b[0m)         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m27 \u001b[0m                                                                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mc:\\Users\\Kang \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mMinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m115 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mc:\\Users\\Kang \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mMinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.p\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33my\u001b[0m:\u001b[94m1604\u001b[0m in \u001b[92mgenerate\u001b[0m                                                                               \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1601 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m**model_kwargs,                                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1602 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m)                                                                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1603 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[2m# 13. run beam search\u001b[0m                                                         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1604 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.beam_search(                                                      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1605 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0minput_ids,                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1606 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mbeam_scorer,                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1607 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mlogits_processor=logits_processor,                                        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mc:\\Users\\Kang \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mMinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.p\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33my\u001b[0m:\u001b[94m2955\u001b[0m in \u001b[92mbeam_search\u001b[0m                                                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m2952 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mnext_tokens = next_tokens % vocab_size                                        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m2953 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m2954 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[2m# stateless\u001b[0m                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m2955 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0mbeam_outputs = beam_scorer.process(                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m2956 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0minput_ids,                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m2957 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mnext_token_scores,                                                        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m2958 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mnext_tokens,                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mc:\\Users\\Kang \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33mMinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\beam_se\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[33march.py\u001b[0m:\u001b[94m238\u001b[0m in \u001b[92mprocess\u001b[0m                                                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0meos_token_id = [eos_token_id]                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m236 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mfor\u001b[0m batch_idx, beam_hyp \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(\u001b[96mself\u001b[0m._beam_hyps):                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m238 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._done[batch_idx]:                                                      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.num_beams < \u001b[96mlen\u001b[0m(beam_hyp):                                         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m240 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mBatch can only be done if at least \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.num_beam   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m241 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m eos_token_id \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m pad_token_id \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
    "                                   model, tokenizer, batch_size=8)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
