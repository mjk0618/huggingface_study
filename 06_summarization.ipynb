{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install nltk\n",
    "# !pip install rogue_metrics\n",
    "# !pip install py7zr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter6 요약\n",
    "## 6.1 CNN/DailyMail 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "print(f\"특성: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 (500개 문자 발췌, 총 길이: 4051):\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "요약 (길이: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"기사 (500개 문자 발췌, 총 길이: {len(sample['article'])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f\"\\n요약 (길이: {len(sample['highlights'])}):\")\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won't do what they're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they're in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the 'forgotten floor' » . At first, it's hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that's kind of what they look like. They're designed to keep the mentally ill patients from injuring themselves. That's also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it's not supposed to be warm and comforting, but the lights glare, the cells are tiny and it's loud. We see two, sometimes three men -- sometimes in the robes, sometimes naked, lying or sitting in their cells. \"I am the son of the president. You need to get me out of here!\" one man shouts at me. He is absolutely serious, convinced that help is on the way -- if only he could reach the White House. Leifman tells me that these prisoner-patients will often circulate through the system, occasionally stabilizing in a mental hospital, only to return to jail to face their charges. It's brutally unjust, in his mind, and he has become a strong advocate for changing things in Miami. Over a meal later, we talk about how things got this way for mental patients. Leifman says 200 years ago people were considered \"lunatics\" and they were locked up in jails even if they had no charges against them. They were just considered unfit to be in society. Over the years, he says, there was some public outcry, and the mentally ill were moved out of jails and into hospitals. But Leifman says many of these mental hospitals were so horrible they were shut down. Where did the patients go? Nowhere. The streets. They became, in many cases, the homeless, he says. They never got treatment. Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals. The judge says he's working to change this. Starting in 2008, many inmates who would otherwise have been brought to the \"forgotten floor\"  will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment, not just punishment. Leifman says it's not the complete answer, but it's a start. Leifman says the best part is that it's a win-win solution. The patients win, the families are relieved, and the state saves money by simply not cycling these prisoners through again and again. And, for Leifman, justice is served. E-mail to a friend .\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][1][\"article\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 텍스트 요약 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "# 딕셔너리에 각 모델이 생성한 요약을 저장합니다.\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset[\"train\"]:\n",
    "    if sample[\"article\"].startswith(\"(CNN)  -- Usain Bolt rounded\"):\n",
    "        print(sample[\"article\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kang\n",
      "[nltk_data]     MinJae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fig.', '2 shows a U.S.A. map.']\n",
      "['Fig. 2 shows a U.S.A. map.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "\n",
    "string = \"Fig. 2 shows a U.S.A. map.\"\n",
    "\n",
    "print(sent_tokenize(string))\n",
    "\n",
    "punkt_param = PunktParameters()\n",
    "abbreviation = ['u.s.a', 'fig']\n",
    "punkt_param.abbrev_types = set(abbreviation)\n",
    "tokenizer = PunktSentenceTokenizer(punkt_param)\n",
    "\n",
    "print(tokenizer.tokenize(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 요약 기준 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(\n",
    "    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': 'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\\nHere, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\\nMIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"',\n",
       " 'gpt2': 'Here\\'s a more \"interesting\" story CNN.com was unable to access.\\nThis story in the Miami Herald\\xa0 is even more disturbing.\\nA video report at 6:00 \\xa0of Leifman\\'s office shows a video of a mentally ill inmate breaking through the bars of a jail cell and making a break for it.\\nThe\\xa0 Miami Herald headline above tells you everything'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 PEGASUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 요약 결과 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUD TRUTH\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "BASELINE\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n",
      "\n",
      "GPT2\n",
      "Here's a more \"interesting\" story CNN.com was unable to access.\n",
      "This story in the Miami Herald  is even more disturbing.\n",
      "A video report at 6:00  of Leifman's office shows a video of a mentally ill inmate breaking through the bars of a jail cell and making a break for it.\n",
      "The  Miami Herald headline above tells you everything\n",
      "\n",
      "T5\n",
      "mentally ill inmates are housed on the ninth floor of a florida jail .\n",
      "most face drug charges or charges of assaulting an officer .\n",
      "judge says arrests often result from confrontations with police .\n",
      "one-third of all people in Miami-dade county jails are mental ill .\n",
      "\n",
      "BART\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n",
      "\n",
      "PEGASUS\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"<n>The ninth floor is where they're held until they're ready to appear in court.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "They end up on the ninth floor severely mentally disturbed .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUD TRUTH\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 생성된 텍스트 품질 평가하기\n",
    "### 6.4.1 BLEU\n",
    "생성된 텍스트에서 얼마나 많은 토큰이 참조 텍스트 토큰과 완벽하게 똑같이 정렬됐는지 확인하는 대신, 단어 또는 n-그램을 체크합니다. 정밀도를 근간으로 하는 지표인데, 두 텍스트를 비교할 때 참조 텍스트에 있는 단어가 생성된 텍스트에 얼마나 자주 등장하는지 카운트하고, 생성된 텍스트 길이로 나눕니다.\n",
    "\n",
    "여기엔 문제가 있는데, 생성된 텍스트에 동일 단어가 반복되고 이 단어가 참조 텍스트에 등장하면, 정밀도가 1이 됩니다. 따라서 BLEU 논문에서는 단어를 참조 텍스트에 등장한 횟수만큼만 카운트합니다.\n",
    "\n",
    "예를 들어 참조 텍스트와 생성된 텍스트가 아래와 같을 때, 정밀도는 수식과 같이 계산됩니다. \\\n",
    "\\\n",
    "참조 텍스트 : `the cat is on the mat` \\\n",
    "생성된 텍스트 : `the the the the the the`\n",
    "\n",
    "$$p_{vanilla} = {6\\over6}$$\n",
    "$$p_{mod} = {2\\over6}$$\n",
    "\n",
    "이를 확장하여, 단어 뿐만 아니라 n-그램도 확인할 수 있습니다. \\\n",
    "생성된 텍스트를 $snt$, 참조 문장을 $snt'$라고 할 때, n-그램에 대한 정밀도를 다음과 같이 계산합니다.\n",
    "\n",
    "$$\n",
    "p_n = {{\\sum_{n-gram \\in snt'}Count_{clip}(n-gram)}\\over{\\sum_{n-gram \\in snt}Count_(n-gram)}}\n",
    "$$\n",
    "\n",
    "반복적인 생성에는 점수를 주지 않도록 분자의 카운트는 클리핑합니다. 앞에서 언급했듯이, 생성된 문장에서 n-그램의 등장 횟수를 카운트 하는 것이 참조 문장에 나타난 횟수로 제한된다는 의미입니다.\n",
    "\n",
    "일반적으로 테스트 세트는 평가할 샘플이 하나 이상이기 때문에 말뭉치 $C$에 있는 모든 샘플에 대해서는 식이 다음과 같이 확장됩니다.\n",
    "\n",
    "$$\n",
    "p_n = {{\\sum_{snt' \\in C}\\sum_{n-gram \\in snt'}Count_{clip}(n-gram)}\\over{\\sum_{snt \\in C}\\sum_{n-gram \\in snt}Count_(n-gram)}}\n",
    "$$\n",
    "\n",
    "위 식은 재현율은 고려하지 않기 때문에 짧은 시퀀스가 긴 문장보다 유리합니다. 따라서 **브레비티 페널티**(brevity penalty)가 도입되었습니다.\n",
    "\n",
    "$$\n",
    "BR = min(1, e^{1-\\ell_{ref}/\\ell_{gen}})\n",
    "$$\n",
    "\n",
    "생성된 텍스트의 길이 $\\ell_{gen}$가 참조 텍스트 $\\ell_{ref}$보다 더 짧을 때 때 지수 항이 작아집니다. 따라서 BP의 값도 작아집니다. \\\n",
    "재현율을 고려하지 않는 이유는 번역 데이터셋에는 보통 여러 개의 참조 문장이 있는데, 재현율을 측정할 경우 참조 문장에 있는 단어를 모두 사용할 경우 가산점이 부여되기 때문입니다.\n",
    "\n",
    "예를 들어 `Good Morning` 이라는 문장을 한국어로 번역할 때, 데이터셋에 다음과 같이 참조 문장이 세 개가 있다고 가정합니다.\n",
    "1. 안녕하세요!\n",
    "2. 좋은 아침이에요!\n",
    "3. 아침이 밝았어요!\n",
    "\n",
    "이 때, 번역된 문장이 `안녕하세요! 좋은 아침이 밝았어요!`와 같이 번역되면 더 높은 점수가 부여되는 문제가 있습니다.\n",
    "\n",
    "앞에서 고려한 모든 것을 합친 BLEU 점수는 다음과 같이 계산합니다.\n",
    "\n",
    "$$\n",
    "\\textrm{BLEU}-N = BR \\times \\left(\\prod_{n=1}^N p_n \\right)^{1/N}\n",
    "$$\n",
    "\n",
    "BLEU는 동의어를 고려하지 않는다는 단점이 있습니다. 그리고 매 단계에서 한계가 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06cf22b3afa4451af22bebe28219cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='c', min=1), IntSlider(value=50, description='r', min=1)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "\n",
    "def brevity_penalty(c, r):\n",
    "    BP = 1 if c > r else np.exp(1 - r / c)\n",
    "    \n",
    "    c_values = np.linspace(0.1, 2 * max(c, r), 400)  \n",
    "    BP_values = np.where(c_values > r, 1, np.exp(1 - r / c_values))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), dpi=100)\n",
    "    plt.plot(c_values, BP_values, label='Brevity Penalty curve', color='blue')\n",
    "    plt.axhline(y=1, color='gray', linestyle='--', lw=0.5)\n",
    "    plt.axvline(x=r, color='red', linestyle='--', label=f'Reference Length (r) = {r}')\n",
    "    plt.axvline(x=c, color='green', linestyle='--', label=f'Candidate Length (c) = {c}')\n",
    "    plt.scatter(c, BP, color='black', s=70, zorder=5)\n",
    "    plt.xlabel('Candidate Length')\n",
    "    plt.ylabel('Brevity Penalty (BP)')\n",
    "    plt.title('Brevity Penalty as function of Candidate Length')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(brevity_penalty, c=(1, 100), r=(1, 100))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "참조 문장의 길이         생성된 문장의 길이         브레비티 페널티\n",
      "50                      5                         0.00012340980408667956\n",
      "50                      25                        0.36787944117144233\n",
      "50                      50                        1.0\n",
      "50                      100                       1\n",
      "50                      150                       1\n"
     ]
    }
   ],
   "source": [
    "ref_len = 50\n",
    "can_lens = [5, 25, 50, 100, 150]\n",
    "\n",
    "print(\"참조 문장의 길이         생성된 문장의 길이         브레비티 페널티\")\n",
    "for can_len in can_lens:\n",
    "    BP = 1 if can_len > ref_len else np.exp(1 - ref_len / can_len)\n",
    "    print(f\"{ref_len:<23} {can_len:<25} {BP}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kang MinJae\\AppData\\Local\\Temp\\ipykernel_14632\\2101912569.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "bleu_metric_new = load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = bleu_metric_new.compute(\n",
    "        predictions=[\"the the the the the the\"], references=[[\"the cat is on the mat\"]], \n",
    "        smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>최종 BLEU 점수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "      <td>매칭된 n-그램의 개수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "      <td>가능한 n-그램의 총 개수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "      <td>각 n-그램에 대한 정밀도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "      <td>브레비티 페널티 값</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "      <td>생성된 텍스트의 길이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "      <td>참조 텍스트의 길이</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value     Description\n",
       "score                          0.0      최종 BLEU 점수\n",
       "counts                [2, 0, 0, 0]    매칭된 n-그램의 개수\n",
       "totals                [6, 5, 4, 3]  가능한 n-그램의 총 개수\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]  각 n-그램에 대한 정밀도\n",
       "bp                             1.0      브레비티 페널티 값\n",
       "sys_len                          6     생성된 텍스트의 길이\n",
       "ref_len                          6      참조 텍스트의 길이"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = {\n",
    "    \"score\": \"최종 BLEU 점수\",\n",
    "    \"counts\": \"매칭된 n-그램의 개수\",\n",
    "    \"totals\": \"가능한 n-그램의 총 개수\",\n",
    "    \"precisions\": \"각 n-그램에 대한 정밀도\",\n",
    "    \"bp\": \"브레비티 페널티 값\",\n",
    "    \"sys_len\": \"생성된 텍스트의 길이\",\n",
    "    \"ref_len\": \"참조 텍스트의 길이\"\n",
    "}\n",
    "\n",
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "df[\"Description\"] = df.index.map(descriptions)  # Map keys to descriptions\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`smooth_value`를 사용하면 분자에 상수 값을 추가합니다. `smooth_method=\"floor\"`일 경우 `smooth_value`는 $0.1$이 됩니다. \\\n",
    "즉 분자에 $+0.1$을 하여 $p_n$을 다음과 같이 계산합니다.\n",
    "\n",
    "$$\n",
    "p_n = \\frac{\\text{n-grams count in reference text} + \\text{smooth value(=0.1)}}{\\text{n-grams in generated text}}\n",
    "$$\n",
    "\n",
    "따라서 bigram에서 겹치는 bigram이 하나도 없지만, 아래와 같이 `smooth_value`에 의해 precision이 $\\frac{0.1}{5} = 0.02$로 계산됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>4.854918</td>\n",
       "      <td>최종 BLEU 점수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "      <td>매칭된 n-그램의 개수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "      <td>가능한 n-그램의 총 개수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 2.0, 2.5, 3.33]</td>\n",
       "      <td>각 n-그램에 대한 정밀도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "      <td>브레비티 페널티 값</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "      <td>생성된 텍스트의 길이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "      <td>참조 텍스트의 길이</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value     Description\n",
       "score                      4.854918      최종 BLEU 점수\n",
       "counts                 [2, 0, 0, 0]    매칭된 n-그램의 개수\n",
       "totals                 [6, 5, 4, 3]  가능한 n-그램의 총 개수\n",
       "precisions  [33.33, 2.0, 2.5, 3.33]  각 n-그램에 대한 정밀도\n",
       "bp                              1.0      브레비티 페널티 값\n",
       "sys_len                           6     생성된 텍스트의 길이\n",
       "ref_len                           6      참조 텍스트의 길이"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\")\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "df[\"Description\"] = df.index.map(descriptions)  # Map keys to descriptions\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 ROUGE\n",
    "\n",
    "ROGUE 점수는 정밀도보다 재현율이 정확한 요약 같은 태스크를 위해 개발되었습니다. n-그램이 얼마나 자주 등장하는지 비교한다는 점에서 BLEU 점수와 비슷하지만, 참조 텍스트에 있는 n-그램이 생성된 텍스트에 얼마나 많이 등장하는지도 확인한다는 점이 다릅니다. 다음이 원래 ROUGE 점수 공식입니다.\n",
    "\n",
    "$$\n",
    "\\textrm{ROUGE}-N = {{\\sum_{snt' \\in C}\\sum_{n-gram \\in snt'}Count_{match}(n-gram)}\\over{\\sum_{snt' \\in C}\\sum_{n-gram \\in snt'}Count_(n-gram)}}\n",
    "$$\n",
    "\n",
    "그런데 정밀도를 완전히 제거하면 부정적인 영향이 커짐을 발견하였고, 클리핑 카운트를 하지 않는 BLEU 공식으로 돌아가 정밀도를 측정한 다음 위의 ROUGE식에서 구한 재현율 점수를 조화 평균한 $\\textrm{F}_1$-점수를 ROUGE 점수로 사용합니다.\n",
    "\n",
    "ROUGE는 가장 긴 공통 부분 시퀀스(longest common subsequence, LCS)를 측정하는 별도의 점수인 ROUGE-L이 있습니다. 두 샘플 사이에서 이 값을 비교할 때, 긴 텍스트가 유리하므로 정규화가 필요합니다. 그래서 ROUGE 개발자는 F-점수와 같은 방식을 고안하였고, 다음과 같이 참조 텍스트와 생성 텍스트의 길이로 LCS를 정규화한 다음 정규화된 점수를 혼합합니다.\n",
    "\n",
    "$$\n",
    "R_{LCS} = \\frac{LCS(X, Y)}{m}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{LCS} = \\frac{LCS(X, Y)}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_{LCS} = \\frac{(1 + \\beta^2)R_{LCS}P_{LCS}}{R_{LCS}+\\beta^2P_{LCS}} ~~~~~~~~ (\\textrm{where, }\\beta = P_{LCS} / R_{LCS})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.288288</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.288288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.323232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714\n",
       "gpt2      0.288288  0.018349  0.162162   0.288288\n",
       "t5        0.382979  0.130435  0.255319   0.382979\n",
       "bart      0.475248  0.222222  0.316832   0.415842\n",
       "pegasus   0.323232  0.206186  0.282828   0.323232"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(predictions=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text=\"article\",\n",
    "                                column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "                     references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.389276</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.245061</td>\n",
       "      <td>0.354239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.389276  0.171296  0.245061   0.354239"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "\n",
    "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\" list_of_elements로부터 batch_size 크기의 청크를 연속적으로 생성합니다. \"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n",
    "                           padding=\"max_length\", return_tensors=\"pt\")\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                                   attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                                   length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                              clean_up_tokenization_spaces=True)\n",
    "                            for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "    \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscore = evaluate_summaries_pegasus(test_sampled, rouge_metric,\\n                                   model, tokenizer, batch_size=8)\\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\\n\\npd.DataFrame(rouge_dict, index=[\"pegasus\"])\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "# 아래 코드는 실행 시간이 너무 오래 걸려서 생략\n",
    "'''\n",
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
    "                                   model, tokenizer, batch_size=8)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 요약 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 크기: [14732, 819, 818]\n",
      "특성: ['id', 'dialogue', 'summary']\n",
      "\n",
      "대화:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "요약:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\")\n",
    "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
    "\n",
    "print(f\"분할 크기: {split_lengths}\")\n",
    "print(f\"특성: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\n대화:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\n요약:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1 SAMSum에서 PEGASUS 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amanda: Ask Larry Amanda: He called her last time we were at the park together.\n",
      "Hannah: I'd rather you texted him.\n",
      "Amanda: Just text him .\n"
     ]
    }
   ],
   "source": [
    "pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간이 너무 오래걸려서 생략\n",
    "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n",
    "                                   tokenizer, column_text=\"dialogue\",\n",
    "                                   column_summary=\"summary\", batch_size=8)\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2 PEGASUS 미세 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x525 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True, dpi=150)\n",
    "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[1].set_title(\"Summary Token Length\")\n",
    "axes[1].set_xlabel(\"Length\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6678e21c9b64ba0b35dd640f742be98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3606: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n",
    "                                truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n",
    "                                     truncation=True)\n",
    "    \n",
    "    return {\"input_ids\": input_encodings[\"input_ids\"],\n",
    "            \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "            \"labels\": target_encodings[\"input_ids\"]}\n",
    "\n",
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, \n",
    "                                       batched=True)\n",
    "\n",
    "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = f\"D:/_MODEL_CHECKPOINT/pegasus-samsum\",\n",
    "    num_train_epochs=1,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=1e6,\n",
    "    gradient_accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간이 너무 오래걸려서 생략\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간이 너무 오래걸려서 생략\n",
    "score = evaluate_summaries_pegasus(\n",
    "    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n",
    "    batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.3 대화 요약 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\": 8, \"max_length\": 128}\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=model) # 체크포인트 불러와야 함\n",
    "\n",
    "print(\"대화:\")\n",
    "print(sample_text)\n",
    "print(\"\\n참조 요약:\")\n",
    "print(reference)\n",
    "print(\"\\n모델 요약:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
