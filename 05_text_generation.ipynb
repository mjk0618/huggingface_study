{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 텍스트 생성\n",
    "## 5.1 일관성 있는 텍스트 생성의 어려움\n",
    "## 5.2 그리디 서치 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff521c13f5184666a53eb927041ea030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kang MinJae\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93d3df1acdd48d89bfc396fe8be1908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259d7346f3d946da992e56f9b92e9e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3233cc48ae47a18f7435f73645e786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7f9ee4fd3047e884364b4d04044b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b917f8763734fce865602a4a7876260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gpt2-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most (11.78)%</td>\n",
       "      <td>best (6.66)%</td>\n",
       "      <td>only (5.62)%</td>\n",
       "      <td>first (2.91)%</td>\n",
       "      <td>ultimate (2.23)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the most</td>\n",
       "      <td>popular (22.63)%</td>\n",
       "      <td>successful (5.55)%</td>\n",
       "      <td>famous (3.38)%</td>\n",
       "      <td>powerful (3.14)%</td>\n",
       "      <td>important (2.54)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the most popular</td>\n",
       "      <td>toys (8.87)%</td>\n",
       "      <td>toy (7.88)%</td>\n",
       "      <td>of (5.03)%</td>\n",
       "      <td>Transformers (4.69)%</td>\n",
       "      <td>franchise (3.88)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the most popular toys</td>\n",
       "      <td>of (31.69)%</td>\n",
       "      <td>in (23.73)%</td>\n",
       "      <td>ever (4.85)%</td>\n",
       "      <td>, (4.50)%</td>\n",
       "      <td>for (3.58)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the most popular toys of</td>\n",
       "      <td>all (57.47)%</td>\n",
       "      <td>the (21.30)%</td>\n",
       "      <td>2015 (2.34)%</td>\n",
       "      <td>their (1.66)%</td>\n",
       "      <td>2014 (1.54)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the most popular toys of all</td>\n",
       "      <td>time (94.71)%</td>\n",
       "      <td>- (1.86)%</td>\n",
       "      <td>. (0.66)%</td>\n",
       "      <td>, (0.56)%</td>\n",
       "      <td>times (0.52)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the most popular toys of all ...</td>\n",
       "      <td>. (34.98)%</td>\n",
       "      <td>, (33.86)%</td>\n",
       "      <td>and (7.03)%</td>\n",
       "      <td>! (2.16)%</td>\n",
       "      <td>in (1.73)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the most popular toys of all ...</td>\n",
       "      <td>They (10.93)%</td>\n",
       "      <td>\\n (9.23)%</td>\n",
       "      <td>The (6.63)%</td>\n",
       "      <td>In (2.91)%</td>\n",
       "      <td>And (2.68)%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input           Choice 1  \\\n",
       "0                               Transformers are the      most (11.78)%   \n",
       "1                          Transformers are the most   popular (22.63)%   \n",
       "2                  Transformers are the most popular       toys (8.87)%   \n",
       "3             Transformers are the most popular toys        of (31.69)%   \n",
       "4          Transformers are the most popular toys of       all (57.47)%   \n",
       "5      Transformers are the most popular toys of all      time (94.71)%   \n",
       "6  Transformers are the most popular toys of all ...         . (34.98)%   \n",
       "7  Transformers are the most popular toys of all ...      They (10.93)%   \n",
       "\n",
       "              Choice 2         Choice 3               Choice 4  \\\n",
       "0         best (6.66)%     only (5.62)%          first (2.91)%   \n",
       "1   successful (5.55)%   famous (3.38)%       powerful (3.14)%   \n",
       "2          toy (7.88)%       of (5.03)%   Transformers (4.69)%   \n",
       "3          in (23.73)%     ever (4.85)%              , (4.50)%   \n",
       "4         the (21.30)%     2015 (2.34)%          their (1.66)%   \n",
       "5            - (1.86)%        . (0.66)%              , (0.56)%   \n",
       "6           , (33.86)%      and (7.03)%              ! (2.16)%   \n",
       "7           \\n (9.23)%      The (6.63)%             In (2.91)%   \n",
       "\n",
       "             Choice 5  \n",
       "0    ultimate (2.23)%  \n",
       "1   important (2.54)%  \n",
       "2   franchise (3.88)%  \n",
       "3         for (3.58)%  \n",
       "4        2014 (1.54)%  \n",
       "5       times (0.52)%  \n",
       "6          in (1.73)%  \n",
       "7         And (2.68)%  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_txt = \"Transformers are the\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        # 첫 번째 배치의 마지막 토큰의 로짓을 선택해 소프트맥스를 적용합니다.\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        # 가장 높은 확률의 토큰을 저장합니다.\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f})%\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx + 1}\"] = token_choice\n",
    "        # 예측한 다음 토큰을 입력에 추가합니다.\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "\n",
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are the most popular toys of all time. They\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The unicorns were discovered by a team of scientists from the University of Colorado, Boulder, who were studying the effects of climate change on the Andes Mountains.\n",
      "\n",
      "\n",
      "The team, led by Dr. David R. Smith, discovered the unicorns in the remote valley of the Andes Mountains, in the Andes Mountains of Chile.\n",
      "\n",
      "\n",
      "The team discovered the unicorns in the\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\ \n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 빔 서치 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_logprob(model, labels, input_len=0):\n",
    "    with torch.no_grad():\n",
    "        output = model(labels)\n",
    "        log_probs = log_probs_from_logits(\n",
    "            output.logits[:, :-1, :], labels[:, 1:]\n",
    "        )\n",
    "        seq_lob_prob = torch.sum(log_probs[:, input_len:])\n",
    "    return seq_lob_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The unicorns were discovered by a team of scientists from the University of Colorado, Boulder, who were studying the effects of climate change on the Andes Mountains.\n",
      "\n",
      "\n",
      "The team, led by Dr. David R. Smith, discovered the unicorns in the remote valley of the Andes Mountains, in the Andes Mountains of Chile.\n",
      "\n",
      "\n",
      "The team discovered the unicorns in the\n",
      "\n",
      "로그 확률: -93.94\n"
     ]
    }
   ],
   "source": [
    "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_greedy[0]))\n",
    "print(f\"\\n로그 확률: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "According to the researchers, the unicorns were found in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "The unicorns were found in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke\n",
      "\n",
      "로그 확률: -28.50\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, do_sample=False)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\n로그 확률: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "According to a press release from the National Geographic Society, a team of scientists led by University of California, Santa Cruz (UCSC) Professor of Ecology and Evolutionary Biology, Richard Wrangham, discovered the unicorn herd while conducting fieldwork in Peru.\n",
      "\n",
      "\"We were surprised to find that there were so many of them, and that they spoke English,\" said Professor W\n",
      "\n",
      "로그 확률: -88.07\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, \n",
    "                             do_sample=False, no_repeat_ngram_size=2)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\n로그 확률: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 샘플링 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "ColumbbottJJFeQ President Top Not Toocul friendly mammalianSposterium indicum deep rocking Toast tion list Column Exp Save propagate repairs Contact packages CE Richardsctthood circa Haram witchcraft descriptions weapon throw SovietsProof figures play contacting Republicans GiveDoStractical\n",
      "\n",
      " improvement elevation breaking morals Fore OrthGood Nah Man Sleeping fists fires innocence fitness growing administration ostcode 820 Zimmerman resign part benevolent possessing standards challenging embassiesigent\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             temperature=2.0, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The unicorns were spotted in the Andes Mountains in Peru, where they have been known to roam for years. The researchers believe that the unicorns are descendants of the Olmecs, a tribe that lived in the area for thousands of years before disappearing.\n",
      "\n",
      "The researchers have been studying the area for years to find the unicorns, but it's not easy to find the\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             temperature=0.5, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 탑-k 및 뉴클리어스 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The team of researchers from the Universidad de Concepción, in Chile, had been studying the animals on the mountain for several years. They had been trying to find out how they were able to communicate with each other, and were surprised to discover that the unicorns were able to speak English.\n",
      "\n",
      "The study, published in the journal PNAS, said that the unicorns\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             temperature=0.5, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The scientists believe the unicorns came to the valley from a location in the mountains to the west, some 5,200 miles to the east, where there are still some of the largest and most extensive unicorns in the world.\n",
      "\n",
      "The creatures were born with only a single horn in their bodies, because they were born with their mother's egg, and thus were not able to make\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             top_p=0.90)\n",
    "print(tokenizer.decode(output_topp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered \\ \n",
      "a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "\"They are talking like a horse in the forest. They are using language we've never heard before and they are behaving like a human,\" says lead researcher, Dr. Richard Dawkins of Cambridge University. \"They are behaving very much like the creatures we thought they would be like.\"\n",
      "\n",
      "\n",
      "The creatures, which have yet to be named or described, first appeared on the Internet in November 2007\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             top_k=50, top_p=0.90)\n",
    "print(tokenizer.decode(output_topp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
